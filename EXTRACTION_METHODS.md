# LaTeX æ‰‹å†Œä¿¡æ¯æå–æ–¹æ³•è¯¦è§£

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¦‚ä½•ä»6ä¸ªä¸åŒçš„LaTeXæ‰‹å†Œä¸­æå–ç»“æ„åŒ–çŸ¥è¯†ã€‚æ¯ä¸ªæ‰‹å†Œéƒ½æœ‰ç‹¬ç‰¹çš„æ–‡æ¡£ç»“æ„å’Œä»£ç ç»„ç»‡æ–¹å¼ï¼Œéœ€è¦å®šåˆ¶åŒ–çš„æå–ç­–ç•¥ã€‚

---

## ğŸ¯ é€šç”¨æå–åŸåˆ™

### 1. çŸ¥è¯†ç±»å‹åˆ†ç±»
æ‰€æœ‰æ‰‹å†Œæå–çš„çŸ¥è¯†ç»Ÿä¸€åˆ†ä¸ºä»¥ä¸‹ç±»å‹ï¼š

```python
KNOWLEDGE_TYPES = {
    "command": "å‘½ä»¤å®šä¹‰",
    "environment": "ç¯å¢ƒå®šä¹‰",
    "executable_example": "å¯æ‰§è¡Œç¤ºä¾‹",
    "key_value": "é”®å€¼å¯¹é…ç½®",
    "component": "ç»„ä»¶å®šä¹‰ï¼ˆcircuitikzä¸“ç”¨ï¼‰",
    "feedback": "è­¦å‘Šå’Œæœ€ä½³å®è·µ"
}
```

### 2. é€šç”¨å…ƒæ•°æ®ç»“æ„

```json
{
  "id": "unique_hash_id",
  "type": "command|environment|executable_example|...",
  "macro_package": "package_name",
  "name": "command_or_component_name",
  "description": "ç®€çŸ­æè¿°",
  "syntax": "å‘½ä»¤è¯­æ³•",
  "parameters": {
    "required": ["arg1", "arg2"],
    "optional": ["opt1", "opt2"]
  },
  "examples": ["example code"],
  "source_file": "path/to/file.tex",
  "line_number": 123,
  "category": "specific_category",
  "tags": ["tag1", "tag2"]
}
```

---

## ğŸŸ¢ ä¸€çº§æ‰‹å†Œæå–æ–¹æ³•

## 1. TIKZ-NETWORK æå–æ–¹æ³•

### æ‰‹å†Œç‰¹å¾
- **æ–‡æ¡£ç¯å¢ƒ**: docspec, docspecdef
- **å‘½ä»¤å®šä¹‰**: `\doccmddef{CommandName}`
- **ä»£ç ç¤ºä¾‹**: lstlistingç¯å¢ƒ
- **å›¾ç¤º**: tikzpicture (å«è¾¹æ³¨marginfigure)

### æå–ç­–ç•¥

#### Step 1: ç« èŠ‚ç»“æ„æå–
```python
import re

def extract_chapters(content):
    """æå–ç« èŠ‚ç»“æ„"""
    pattern = r'\\chapter\{([^}]+)\}'
    chapters = re.findall(pattern, content)

    section_pattern = r'\\section\{([^}]+)\}'
    sections = re.findall(section_pattern, content)

    return {
        "chapters": chapters,
        "sections": sections
    }
```

#### Step 2: å‘½ä»¤å®šä¹‰æå–
```python
def extract_commands(content):
    """æå–å‘½ä»¤å®šä¹‰"""
    items = []

    # åŒ¹é… \doccmddef{CommandName}
    pattern = r'\\doccmddef\{([^}]+)\}'
    matches = re.finditer(pattern, content)

    for match in matches:
        cmd_name = match.group(1)

        # æŸ¥æ‰¾åç»­çš„ docspecdef ç¯å¢ƒ
        start_pos = match.end()
        docspec_pattern = r'\\begin\{docspecdef\}(.*?)\\end\{docspecdef\}'
        docspec_match = re.search(docspec_pattern, content[start_pos:], re.DOTALL)

        if docspec_match:
            syntax = docspec_match.group(1)

            items.append({
                "type": "command",
                "macro_package": "tikz-network",
                "name": cmd_name,
                "syntax": extract_syntax(syntax),
                "source_file": "tikz-network.tex"
            })

    return items

def extract_syntax(syntax_text):
    """ä»docspecä¸­æå–è¯­æ³•"""
    # æå– \docopt{} å’Œ \docarg{}
    opts = re.findall(r'\\docopt\{([^}]+)\}', syntax_text)
    args = re.findall(r'\\docarg\{([^}]+)\}', syntax_text)

    return {
        "optional": opts,
        "required": args
    }
```

#### Step 3: é€‰é¡¹è¡¨æ ¼æå–
```python
def extract_option_tables(content):
    """æå–é€‰é¡¹è¡¨æ ¼"""
    items = []

    # æŸ¥æ‰¾ tabular ç¯å¢ƒ
    pattern = r'\\begin\{tabular\}\{([^}]+)\}(.*?)\\end\{tabular\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for match in matches:
        table_content = match.group(2)

        # è§£æè¡¨æ ¼è¡Œ
        rows = table_content.split('\\\\')
        for row in rows[1:]:  # è·³è¿‡è¡¨å¤´
            cells = row.split('&')
            if len(cells) >= 3:
                option_name = cells[0].strip()
                default_value = cells[1].strip()
                description = cells[2].strip()

                items.append({
                    "type": "key_value",
                    "macro_package": "tikz-network",
                    "key": option_name,
                    "default": default_value,
                    "description": description
                })

    return items
```

#### Step 4: ä»£ç ç¤ºä¾‹æå–
```python
def extract_examples(content):
    """æå–lstlistingç¤ºä¾‹"""
    items = []

    pattern = r'\\begin\{lstlisting\}(.*?)\\end\{lstlisting\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for idx, match in enumerate(matches):
        code = match.group(1).strip()

        # æ£€æµ‹æ˜¯å¦åŒ…å«tikz-networkå‘½ä»¤
        if '\\Vertex' in code or '\\Edge' in code:
            items.append({
                "type": "executable_example",
                "macro_package": "tikz-network",
                "code": code,
                "chart_type": "network_graph",
                "id": f"tikz-network-ex-{idx}"
            })

    return items
```

### å®Œæ•´æå–æµç¨‹
```python
class TikzNetworkExtractor:
    def __init__(self, manual_path):
        self.manual_path = manual_path

    def process(self):
        with open(self.manual_path, 'r', encoding='utf-8') as f:
            content = f.read()

        knowledge_items = []
        knowledge_items.extend(extract_chapters(content))
        knowledge_items.extend(extract_commands(content))
        knowledge_items.extend(extract_option_tables(content))
        knowledge_items.extend(extract_examples(content))

        return knowledge_items
```

---

## 2. CHEMFIG æå–æ–¹æ³•

### æ‰‹å†Œç‰¹å¾
- **è‡ªå®šä¹‰å®**: `\exemple`, `\exemple*`
- **åˆ†éš”ç¬¦**: ä½¿ç”¨ `/` æˆ– `|` åˆ†éš”ä»£ç 
- **é”®å€¼ç³»ç»Ÿ**: `\CFkey{}`, `\CFkv{}{}`
- **ç‰¹æ®Šè¯­æ³•**: catcodeæŠ€å·§

### æå–ç­–ç•¥

#### Step 1: è¯†åˆ«\exempleå®
```python
def extract_chemfig_examples(content):
    """æå–chemfigçš„\exempleå®"""
    items = []

    # åŒ¹é… \exemple{title}/code/
    pattern = r'\\exemple(\*)?(?:\[([^\]]*)\])?\{([^/\|]*)\}([/\|])(.*?)\4'
    matches = re.finditer(pattern, content, re.DOTALL)

    for idx, match in enumerate(matches):
        is_starred = match.group(1) is not None
        ratio = match.group(2) or "65"
        title = match.group(3)
        delimiter = match.group(4)
        code = match.group(5).strip()

        items.append({
            "type": "executable_example",
            "macro_package": "chemfig",
            "title": title,
            "code": code,
            "display_mode": "full_width" if is_starred else "split",
            "ratio": ratio,
            "chart_type": "chemical_structure",
            "id": f"chemfig-ex-{idx}"
        })

    return items
```

#### Step 2: æå–é”®å€¼å¯¹æ–‡æ¡£
```python
def extract_chemfig_keys(content):
    """æå–chemfigçš„é”®å€¼å¯¹æ–‡æ¡£"""
    items = []

    # æå– \CFkey{keyname}
    key_pattern = r'\\CFkey\{([^}]+)\}'
    keys = re.finditer(key_pattern, content)

    for match in keys:
        key_name = match.group(1)

        # åœ¨é™„è¿‘æŸ¥æ‰¾æè¿°æ–‡æœ¬
        start = match.end()
        description = extract_nearby_text(content, start, 200)

        items.append({
            "type": "key_value",
            "macro_package": "chemfig",
            "key": key_name,
            "description": description
        })

    # æå– \CFkv{key}{value}
    kv_pattern = r'\\CFkv\{([^}]+)\}\{([^}]+)\}'
    kvs = re.finditer(kv_pattern, content)

    for match in kvs:
        key = match.group(1)
        value = match.group(2)

        items.append({
            "type": "key_value",
            "macro_package": "chemfig",
            "key": key,
            "default": value
        })

    return items
```

#### Step 3: æå–å‘½ä»¤æ–‡æ¡£
```python
def extract_chemfig_commands(content):
    """æå–chemfigå‘½ä»¤"""
    items = []

    # chemfigçš„ä¸»è¦å‘½ä»¤
    main_commands = [
        r'\\chemfig',
        r'\\setchemfig',
        r'\\schemename',
        r'\\chemrel',
        r'\\setlewis',
        r'\\lewis'
    ]

    for cmd_pattern in main_commands:
        # åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾å‘½ä»¤é¦–æ¬¡å‡ºç°
        pattern = f'{cmd_pattern}(?:\\[([^\\]]*)])?(?:\\{{([^}}]*)\\}})?'
        matches = re.finditer(pattern, content)

        for match in matches:
            cmd_name = cmd_pattern.replace('\\\\', '')
            opt_args = match.group(1)
            req_args = match.group(2)

            items.append({
                "type": "command",
                "macro_package": "chemfig",
                "name": cmd_name,
                "optional_args": opt_args,
                "required_args": req_args
            })
            break  # åªå–ç¬¬ä¸€æ¬¡å‡ºç°

    return items
```

#### Step 4: å¤„ç†ç‰¹æ®Šè¯­æ³•
```python
def extract_chemfig_syntax(content):
    """æå–chemfigçš„åŒ–å­¦è¯­æ³•è§„åˆ™"""
    items = []

    # åŒ–å­¦é”®ç±»å‹
    bond_types = {
        '-': 'single bond',
        '=': 'double bond',
        '~': 'triple bond',
        '>': 'right bond',
        '<': 'left bond',
        '>:': 'Cram bond (front)',
        '<:': 'Cram bond (back)'
    }

    for symbol, description in bond_types.items():
        items.append({
            "type": "syntax_rule",
            "macro_package": "chemfig",
            "symbol": symbol,
            "description": description,
            "category": "bond_type"
        })

    return items
```

### å®Œæ•´æå–æµç¨‹
```python
class ChemfigExtractor:
    def __init__(self, manual_dir):
        self.manual_dir = Path(manual_dir)

    def process(self):
        main_file = self.manual_dir / "chemfig-en.tex"

        with open(main_file, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        items = []
        items.extend(extract_chemfig_examples(content))
        items.extend(extract_chemfig_keys(content))
        items.extend(extract_chemfig_commands(content))
        items.extend(extract_chemfig_syntax(content))

        return items
```

---

## ğŸŸ¡ äºŒçº§æ‰‹å†Œæå–æ–¹æ³•

## 3. CIRCUITIKZ æå–æ–¹æ³•

### æ‰‹å†Œç‰¹å¾
- **ç»„ä»¶æè¿°**: `\circuitdesc`, `\circuitdescbip`
- **ç¤ºä¾‹ç¯å¢ƒ**: LTXexample (showexplåŒ…)
- **ä»£ç å±•ç¤º**: lstlisting
- **è‡ªå®šä¹‰å·¥å…·**: ctikzmanutils.sty

### æå–ç­–ç•¥

#### Step 1: ç»„ä»¶å®šä¹‰æå–
```python
def extract_circuitikz_components(content):
    """æå–circuitikzç»„ä»¶å®šä¹‰"""
    items = []

    # åŒ¹é… \circuitdesc*{name}{description}{}(anchors)
    pattern = r'\\circuitdesc(\*)?(?:\[([^\]]*)\])?\{([^}]+)\}\{([^}]+)\}\{([^}]*)\}\(([^)]+)\)'
    matches = re.finditer(pattern, content)

    for match in matches:
        is_fillable = match.group(1) is not None
        options = match.group(2)
        component_name = match.group(3)
        description = match.group(4)
        aliases = match.group(5)
        anchors_spec = match.group(6)

        # è§£æé”šç‚¹
        anchors = parse_anchors(anchors_spec)

        items.append({
            "type": "component",
            "macro_package": "circuitikz",
            "component_type": "node",
            "name": component_name,
            "description": description,
            "aliases": aliases.split(',') if aliases else [],
            "fillable": is_fillable,
            "anchors": anchors
        })

    # åŒ¹é… \circuitdescbip{name}{description}{aliases}
    bipolar_pattern = r'\\circuitdescbip(?:\[([^\]]*)\])?\{([^}]+)\}\{([^}]+)\}\{([^}]*)\}'
    bip_matches = re.finditer(bipolar_pattern, content)

    for match in bip_matches:
        options = match.group(1)
        component_name = match.group(2)
        description = match.group(3)
        aliases = match.group(4)

        items.append({
            "type": "component",
            "macro_package": "circuitikz",
            "component_type": "bipole",
            "name": component_name,
            "description": description,
            "aliases": aliases.split(',') if aliases else []
        })

    return items

def parse_anchors(anchors_spec):
    """è§£æé”šç‚¹è§„èŒƒ: name/angle/distance"""
    anchors = []
    for anchor_str in anchors_spec.split(','):
        parts = anchor_str.strip().split('/')
        if len(parts) >= 3:
            anchors.append({
                "name": parts[0].strip(),
                "angle": parts[1].strip(),
                "distance": parts[2].strip()
            })
    return anchors
```

#### Step 2: LTXexampleç¯å¢ƒæå–
```python
def extract_ltxexamples(content):
    """æå–LTXexampleç¯å¢ƒ"""
    items = []

    pattern = r'\\begin\{LTXexample\}(?:\[([^\]]*)\])?(.*?)\\end\{LTXexample\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for idx, match in enumerate(matches):
        options = match.group(1) or ""
        code = match.group(2).strip()

        # è§£æé€‰é¡¹
        opts = parse_ltx_options(options)

        items.append({
            "type": "executable_example",
            "macro_package": "circuitikz",
            "code": code,
            "chart_type": "circuit",
            "display_options": opts,
            "id": f"circuitikz-ex-{idx}"
        })

    return items

def parse_ltx_options(options_str):
    """è§£æLTXexampleé€‰é¡¹"""
    opts = {}
    if not options_str:
        return opts

    # varwidth, pos, presetç­‰
    for opt in options_str.split(','):
        if '=' in opt:
            key, value = opt.split('=', 1)
            opts[key.strip()] = value.strip()
        else:
            opts[opt.strip()] = True

    return opts
```

#### Step 3: é…ç½®é”®æå–
```python
def extract_circuitikz_keys(content):
    """æå–circuitikzé…ç½®é”®"""
    items = []

    # æŸ¥æ‰¾ \ctikzset{key=value} æˆ– \tikzset{key=value}
    set_patterns = [
        r'\\ctikzset\{([^}]+)\}',
        r'\\tikzset\{([^}]+)\}'
    ]

    for pattern in set_patterns:
        matches = re.finditer(pattern, content)
        for match in matches:
            kv_content = match.group(1)

            # è§£æé”®å€¼å¯¹
            kvs = parse_key_values(kv_content)
            for key, value in kvs.items():
                items.append({
                    "type": "key_value",
                    "macro_package": "circuitikz",
                    "key": key,
                    "default": value
                })

    return items
```

#### Step 4: é€‰é¡¹è¡¨æ ¼æå–
```python
def extract_component_options(content):
    """æå–ç»„ä»¶é€‰é¡¹è¡¨æ ¼"""
    items = []

    # åœ¨æ¯ä¸ªç»„ä»¶æè¿°åï¼Œé€šå¸¸æœ‰é€‰é¡¹è¡¨æ ¼
    # æŸ¥æ‰¾ tabular ç¯å¢ƒ
    pattern = r'\\begin\{tabular\}\{[^}]+\}(.*?)\\end\{tabular\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for match in matches:
        table_content = match.group(1)
        rows = parse_booktabs_table(table_content)

        for row in rows:
            if len(row) >= 2:
                items.append({
                    "type": "component_option",
                    "macro_package": "circuitikz",
                    "option": row[0],
                    "description": row[1],
                    "default": row[2] if len(row) > 2 else None
                })

    return items

def parse_booktabs_table(table_content):
    """è§£æbooktabsè¡¨æ ¼"""
    rows = []
    lines = table_content.split('\\\\')

    for line in lines:
        # è·³è¿‡ \toprule, \midrule, \bottomrule
        if 'rule' in line:
            continue

        cells = [cell.strip() for cell in line.split('&')]
        if cells and cells[0]:
            rows.append(cells)

    return rows[1:]  # è·³è¿‡è¡¨å¤´
```

### å®Œæ•´æå–æµç¨‹
```python
class CircuitikzExtractor:
    def __init__(self, manual_dir):
        self.manual_dir = Path(manual_dir)

    def process(self):
        main_file = self.manual_dir / "circuitikzmanual.tex"

        with open(main_file, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        items = []
        items.extend(extract_circuitikz_components(content))
        items.extend(extract_ltxexamples(content))
        items.extend(extract_circuitikz_keys(content))
        items.extend(extract_component_options(content))

        return items
```

---

## ğŸ”´ ä¸‰çº§æ‰‹å†Œæå–æ–¹æ³•

## 4. TKZ-EUCLIDE æå–æ–¹æ³•

### æ‰‹å†Œç‰¹å¾
- **å¤šæ–‡ä»¶ç»“æ„**: 32ä¸ªtexæ–‡ä»¶
- **è‡ªå®šä¹‰ç¯å¢ƒ**: NewMacroBox
- **ç¤ºä¾‹ç¯å¢ƒ**: tkzexample
- **æ–‡æ¡£ç±»**: tkz-doc

### æå–ç­–ç•¥

#### Step 1: å¤„ç†å¤šæ–‡ä»¶ç»“æ„
```python
class TkzEuclideExtractor:
    def __init__(self, manual_dir):
        self.manual_dir = Path(manual_dir)
        self.main_file = self.manual_dir / "TKZdoc-euclide-main.tex"

    def get_file_order(self):
        """ä»mainæ–‡ä»¶è·å–è¾“å…¥é¡ºåº"""
        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå– \input{filename}
        pattern = r'\\input\{([^}]+)\}'
        matches = re.findall(pattern, content)

        return [self.manual_dir / f"{name}.tex" for name in matches]

    def process(self):
        """æŒ‰é¡ºåºå¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        files = self.get_file_order()
        all_items = []

        for file_path in files:
            if file_path.exists():
                items = self.process_file(file_path)
                all_items.extend(items)

        return all_items
```

#### Step 2: NewMacroBoxç¯å¢ƒæå–
```python
def extract_newmacrobox(content, source_file):
    """æå–NewMacroBoxç¯å¢ƒ"""
    items = []

    # åŒ¹é… \begin{NewMacroBox}{commandname}{syntax}
    pattern = r'\\begin\{NewMacroBox\}\{([^}]+)\}\{([^}]+)\}(.*?)\\end\{NewMacroBox\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for match in matches:
        cmd_name = match.group(1)
        syntax = match.group(2)
        body = match.group(3)

        # è§£æsyntaxä¸­çš„å‚æ•°
        params = parse_tkz_syntax(syntax)

        # æå–tabularè¡¨æ ¼
        tables = extract_tables_from_body(body)

        items.append({
            "type": "command",
            "macro_package": "tkz-euclide",
            "name": cmd_name,
            "syntax": syntax,
            "parameters": params,
            "arguments_table": tables.get("arguments", []),
            "options_table": tables.get("options", []),
            "source_file": str(source_file)
        })

    return items

def parse_tkz_syntax(syntax):
    """è§£ætkzå‘½ä»¤è¯­æ³•"""
    params = {
        "optional": [],
        "required": []
    }

    # \oarg{} - optional argument
    opt_pattern = r'\\oarg\{([^}]+)\}'
    params["optional"] = re.findall(opt_pattern, syntax)

    # \marg{} - mandatory argument
    req_pattern = r'\\marg\{([^}]+)\}'
    params["required"] = re.findall(req_pattern, syntax)

    # \parg{} - parenthesized argument
    paren_pattern = r'\\parg\{([^}]+)\}'
    params["parenthesized"] = re.findall(paren_pattern, syntax)

    return params

def extract_tables_from_body(body):
    """ä»NewMacroBox bodyä¸­æå–è¡¨æ ¼"""
    tables = {}

    # æŸ¥æ‰¾åŒ…å« "arguments" çš„è¡¨æ ¼
    arg_pattern = r'arguments.*?\\begin\{tabular\}(.*?)\\end\{tabular\}'
    arg_match = re.search(arg_pattern, body, re.DOTALL | re.IGNORECASE)

    if arg_match:
        tables["arguments"] = parse_tkz_table(arg_match.group(1))

    # æŸ¥æ‰¾åŒ…å« "options" çš„è¡¨æ ¼
    opt_pattern = r'options.*?\\begin\{tabular\}(.*?)\\end\{tabular\}'
    opt_match = re.search(opt_pattern, body, re.DOTALL | re.IGNORECASE)

    if opt_match:
        tables["options"] = parse_tkz_table(opt_match.group(1))

    return tables

def parse_tkz_table(table_content):
    """è§£ætkzè¡¨æ ¼ï¼ˆä½¿ç”¨TAline/TOlineå®ï¼‰"""
    rows = []

    # \TAline{name}{default}{description}
    ta_pattern = r'\\TAline\{([^}]*)\}\{([^}]*)\}\{([^}]*)\}'
    ta_matches = re.finditer(ta_pattern, table_content)

    for match in ta_matches:
        rows.append({
            "name": match.group(1),
            "default": match.group(2),
            "description": match.group(3),
            "type": "argument"
        })

    # \TOline{name}{default}{description}
    to_pattern = r'\\TOline\{([^}]*)\}\{([^}]*)\}\{([^}]*)\}'
    to_matches = re.finditer(to_pattern, table_content)

    for match in to_matches:
        rows.append({
            "name": match.group(1),
            "default": match.group(2),
            "description": match.group(3),
            "type": "option"
        })

    return rows
```

#### Step 3: tkzexampleç¯å¢ƒæå–
```python
def extract_tkzexamples(content, source_file):
    """æå–tkzexampleç¯å¢ƒ"""
    items = []

    pattern = r'\\begin\{tkzexample\}(?:\[([^\]]*)\])?(.*?)\\end\{tkzexample\}'
    matches = re.finditer(pattern, content, re.DOTALL)

    for idx, match in enumerate(matches):
        options = match.group(1) or ""
        code = match.group(2).strip()

        # è§£æé€‰é¡¹
        opts = parse_tkz_options(options)

        items.append({
            "type": "executable_example",
            "macro_package": "tkz-euclide",
            "code": code,
            "chart_type": "geometry",
            "display_options": opts,
            "source_file": str(source_file),
            "id": f"tkz-ex-{source_file.stem}-{idx}"
        })

    return items

def parse_tkz_options(options_str):
    """è§£ætkzexampleé€‰é¡¹"""
    opts = {}
    if not options_str:
        return opts

    # å¸¸è§é€‰é¡¹: latex=7cm, small, vbox, code only
    for opt in options_str.split(','):
        opt = opt.strip()
        if '=' in opt:
            key, value = opt.split('=', 1)
            opts[key.strip()] = value.strip()
        else:
            opts[opt] = True

    return opts
```

#### Step 4: å‘½ä»¤åˆ†ç±»
```python
def categorize_tkz_commands(items):
    """æ ¹æ®å‘½ä»¤å‰ç¼€åˆ†ç±»"""
    categories = {
        "tkzDef": "definition",
        "tkzGet": "retrieval",
        "tkzCalc": "calculation",
        "tkzDraw": "drawing",
        "tkzMark": "marking",
        "tkzLabel": "labeling",
        "tkzFill": "filling",
        "tkzClip": "clipping",
        "tkzSetUp": "setup"
    }

    for item in items:
        if item["type"] == "command":
            cmd_name = item["name"]
            for prefix, category in categories.items():
                if cmd_name.startswith(prefix):
                    item["category"] = category
                    break

    return items
```

### å®Œæ•´æå–æµç¨‹
```python
class TkzEuclideExtractor:
    def process_file(self, file_path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        items = []
        items.extend(extract_newmacrobox(content, file_path))
        items.extend(extract_tkzexamples(content, file_path))

        # åˆ†ç±»
        items = categorize_tkz_commands(items)

        return items
```

---

## ğŸ› ï¸ è¾…åŠ©å·¥å…·å‡½æ•°

### é€šç”¨LaTeXè§£æ
```python
def extract_nearby_text(content, start_pos, max_length=200):
    """æå–é™„è¿‘çš„çº¯æ–‡æœ¬æè¿°"""
    text = content[start_pos:start_pos+max_length]

    # ç§»é™¤LaTeXå‘½ä»¤
    text = re.sub(r'\\[a-zA-Z]+', '', text)
    # ç§»é™¤èŠ±æ‹¬å·
    text = re.sub(r'[{}]', '', text)
    # è§„èŒƒåŒ–ç©ºç™½
    text = ' '.join(text.split())

    return text

def clean_latex_text(text):
    """æ¸…ç†LaTeXæ–‡æœ¬"""
    # ç§»é™¤æ³¨é‡Š
    text = re.sub(r'%.*$', '', text, flags=re.MULTILINE)
    # ç§»é™¤å¤šä½™ç©ºç™½
    text = ' '.join(text.split())
    return text

def parse_key_values(kv_string):
    """è§£æé”®å€¼å¯¹å­—ç¬¦ä¸²"""
    kvs = {}
    # ç®€å•çš„é”®å€¼å¯¹è§£æï¼ˆä¸å¤„ç†åµŒå¥—ï¼‰
    pairs = kv_string.split(',')
    for pair in pairs:
        if '=' in pair:
            key, value = pair.split('=', 1)
            kvs[key.strip()] = value.strip()
    return kvs
```

### IDç”Ÿæˆ
```python
import hashlib

def generate_id(base_string):
    """ç”Ÿæˆå”¯ä¸€ID"""
    return hashlib.md5(base_string.encode()).hexdigest()[:12]
```

---

## ğŸ“Š è´¨é‡è¯„åˆ†ç³»ç»Ÿ

### ç¤ºä¾‹è´¨é‡è¯„åˆ†
```python
def score_example(example_item):
    """ä¸ºç¤ºä¾‹è¯„åˆ†"""
    score = 0

    # ä»£ç é•¿åº¦åˆç†
    code_length = len(example_item["code"])
    if 50 < code_length < 500:
        score += 0.3

    # æœ‰æ³¨é‡Š
    if '%' in example_item["code"]:
        score += 0.2

    # ç»“æ„å®Œæ•´
    if '\\begin{tikzpicture}' in example_item["code"] and \
       '\\end{tikzpicture}' in example_item["code"]:
        score += 0.3

    # ä¸å¤ªå¤æ‚
    if example_item["code"].count('\\') < 20:
        score += 0.2

    return min(score, 1.0)
```

---

## ğŸ”§ ç»Ÿä¸€æ¥å£

### æå–å™¨å·¥å‚
```python
class ExtractorFactory:
    @staticmethod
    def create(package_name, manual_dir):
        extractors = {
            "tikz-network": TikzNetworkExtractor,
            "chemfig": ChemfigExtractor,
            "circuitikz": CircuitikzExtractor,
            "tkz-euclide": TkzEuclideExtractor
        }

        extractor_class = extractors.get(package_name)
        if extractor_class:
            return extractor_class(manual_dir)
        else:
            raise ValueError(f"Unknown package: {package_name}")
```

### æ‰¹é‡å¤„ç†
```python
def process_all_manuals(base_dir):
    """å¤„ç†æ‰€æœ‰æ‰‹å†Œ"""
    packages = [
        "tikz-network",
        "chemfig",
        "circuitikz",
        "tkz-euclide"
    ]

    all_knowledge = []

    for package in packages:
        manual_dir = Path(base_dir) / f"{package}-manual"
        extractor = ExtractorFactory.create(package, manual_dir)

        items = extractor.process()
        all_knowledge.extend(items)

        print(f"Processed {package}: {len(items)} items")

    return all_knowledge
```

---

**æ–‡æ¡£åˆ›å»ºæ—¥æœŸ**: 2025-02-14
**è¦†ç›–æ‰‹å†Œ**: 6ä¸ªLaTeXå®åŒ…æ‰‹å†Œ
**æå–ç±»å‹**: å‘½ä»¤ã€ç¯å¢ƒã€ç¤ºä¾‹ã€é”®å€¼å¯¹ã€ç»„ä»¶
